<!DOCTYPE html>
<html>
  <head>
    <title>Deep Learning Lectures</title>
    <meta charset="utf-8">
    <style>
     .left-column {
       width: 50%;
       float: left;
     }
     .right-column {
       width: 50%;
       float: right;
     }
     .footnote {
        position: absolute;
        bottom: 2em;
        margin: 0em 2em;
     }
     .grey { color: #bbbbbb; }
      </style>
    <link rel="stylesheet" type="text/css" href="slides.css">
  </head>
  <body>
      <textarea id="source">
class: center, middle

# Class imbalance and Metric Learning

Charles Ollion - Olivier Grisel

.affiliations[
  ![Heuritech](images/logo heuritech v2.png)
  ![Inria](images/inria-logo.png)
  ![UPS](images/Logo_Master_Datascience.png)
]

---
## Classic Deep Learning data setup

- Classification with a single label per sample
- 2-1000 classes ; 1000 samples per class

--

### real life problems

What if I have multiple classes per sample?

--

What if I have unbalanced or noisy labels?

--

what if I have 1M classes and 10 samples / class?

---
## Outline

### Multi-labeling and Sampling strategies

--

### Metric Learning and siamese networks

--

### Triplet Loss and advanced techniques

---
class: middle, center

# Multi-labeling and Sampling strategies

---
## From Classification to multilabel

_Object detection is multilabel!_

Classif classification

```python
# ...
x = Convolution2D(2048, 3)(x)
x = GlobalAveragePooling2D()(x)
x = Dense(1000, activation="softmax")(x)
```

---
## From Classification to multilabel

_Object detection is multilabel!_

Replace `softmax` with `sigmoid` activation

```python
# ...
x = Convolution2D(2048, 3)(x)
x = GlobalAveragePooling2D()(x)
x = Dense(1000, activation="sigmoid")(x)
```

--

Similar to having a binary classifier for each class

$y^{\true}$ is a binary vector corresponding to classes present in the image.

--

**problem** : hard to label images for ALL possible tags!

---
# Weak supervision

.center[
          <img src="images/flickr.png" style="width: 300px;" />
]

.footnote.small[
Joulin, Armand, et al. "Learning visual features from large weakly supervised data." ECCV, 2016
]

--

- **Output dimension** (vocabulary) is huge: ~100 000

--
- After stopword removal, **importance sampling** of positive labels

--
- Do not compute the full softmax, **randomly sample negatives**

---

## Inference tricks

Train in weak classification scheme

**How to measure precision/recall?**

- build a (smaller) fully labeled test set

--

**How to interpret the score?**

- **Consistent across tags:** A score of 0.8 for “cat” classifier ~ same meaning as score of 0.8 for the “flower” classifier
- **Interpretable:** Score should reflect the posterior of a tag being present in an image, e.g. p(dog|image)

--

Compute a biais for each class depending on a fully labeled set

.footnote.small[
Garrigues, P., Farfade, S., Izadinia, H., Boakye, K., & Kalantidis, Y. (2016). Tag prediction at flickr: a view from the darkroom. NIPS workshop on large scale CV 2016
]

---
class: middle, center

# Metric Learning & Siamese networks

---
## Few Examples per class

ex: Face Recognition/Verification

--

.center[
          <img src="images/lfw.png" style="width: 500px;" />
]

- Recognition: Given a face, classify among K possible persons
- Verification: verify that two faces belongs to the same person

--

A verification system = similarity measure. If it's really good, useful for recognition
---
## Learning a distance function


We want to build $d_{\theta}( x_1, x_2 )$ which indicates degree of difference between images

--

we define $T$ such that if $d_{\theta}( x_1, x_2 ) < T$, we consider $x_1$ and $x_2$ to be of the same class (e.g. identity)

--

**Not a real distance** (no guarantee for triangle inequality)

--

<br/>

To go further Mahalanobis distance Metric Learning
.small[(more theoretical framework, but limited to linear projections, much less useful for images)]

.footnote.small[
Weinberger, Kilian Q., John Blitzer, and Lawrence K. Saul. "Distance metric learning for large margin nearest neighbor classification." Advances in neural information processing systems. 2006.
]

---
## Learning a distance function

$$
d\_{\theta}( x\_1, x\_2 ) = || f\_{\theta}(x\_1) - f\_{\theta}(x\_2) ||\_2
$$

--

$f_{\theta}$ is typically a CNN which outputs a fixed dense  $\mathbb{R}^d$ representation of the image.

$f_{\theta}$ maps image space to a **representation space** where a simple metric (e.g.
euclidean distance) represents **semantic distance**.

--

For other problems (sound, NLP), different networks may be used (RNNs, ...) which
output a fixed dimension vector representing the data.

--

Training $f_{\theta}$ is also called **representation learning**

---
## Siamese networks

.center[
          <img src="images/siamese.svg" style="width: 500px;" />
]

.footnote.small[
Chopra, Sumit, Raia Hadsell, and Yann LeCun. "Learning a similarity metric discriminatively, with application to face verification." CVPR 2005.
]

---
## Loss function

.center[
          <img src="images/contrastive.png" style="width: 300px;" />
]

**Contrastive loss:** Pushes together similar class pairs, and further away different class ones, up to a margin.

.footnote.small[
Chopra, Sumit, Raia Hadsell, and Yann LeCun. "Learning a similarity metric discriminatively, with application to face verification." CVPR 2005.
]

---
## Alternative loss functions

Can derive equivalent contrastive loss for cosine similarity:


$$cosine(f\_{\theta}(x\_1), f\_{\theta}(x\_2))$$

--

Alternatively, **absolute difference + Binary classification**:

$$y = sigmoid ( \mathbf{w} \cdot |f\_{\theta}(x\_1) - f\_{\theta}(x\_2)| + b)$$


--

Also, **concat + Binary classification**

$$y = sigmoid ( \mathbf{w} \cdot f\_{\theta}(x\_1) ||  f\_{\theta}(x\_2) + b)$$


--

Simpler, often less effective: simple regression after cosine similarity

---
## Training

- sample positive pairs $(x_i, x_j)$, with $(i, j)$ of similar class
- sample negative pairs $(x_i, x_j)$, with $(i, j)$ of different class

.footnote.small[
Taigman et. al., 2014. DeepFace closing the gap to human level performance
]

--


Forward pass using both inputs through the two networks

--

backpropagate through the two networks (same weights are updated twice)

--

Important to **craft batches carefully** (balance positive and negative, group positives together)

???
better to group pairs rather than pick random positive and negatives
Can be tricky to train, sensible on input
---
## Dataset Face verification

**Labeled Faces in the Wild (LFW)**

13,000 pictures, 1680 identities with at least 2 pictures

--

- results http://vis-www.cs.umass.edu/lfw/results.html
- DeepFace: 0.9735 classification accuracy

.footnote.small[
Taigman et. al., 2014. DeepFace closing the gap to human level performance
]

--

**YouTube Faces Database**

3,425 videos of 1,595 different people averaging 181 frames per video

---
## Cars196, CUB200, Online Products

.center[
          <img src="images/class_cars.jpg" style="width: 760px;" />
]

16,185 images of 196 classes of cars

--

.center[
          <img src="images/onlineproduct.png" style="width: 400px;" />
]

120,053 images, 22,634 Online Products (classes) from eBay.com. 5.3 images per class

???

Typically any dataset with large number of classes
Any classification dataset (but softmax classification can be better)

---
class: middle, center

# Triplet Loss

---
## Triplet Loss

A triplet: $(x^a, x^{+}, x^{-})$
- an anchor image
- positive image (same person as anchor)
- negative image (different person as enchor)

We compute $f_{\theta}$ for each of these 3 images

--
We want that:

$||f(x^a) - f(x^{+})||_2 \leq ||f(x^a) - f(x^{-})||_2$

--

$||f(x^a) - f(x^{+})||_2 - ||f(x^a) - f(x^{-})||_2 \leq 0$

--

$||f(x^a) - f(x^{+})||_2 - ||f(x^a) - f(x^{-})||_2 \leq - \alpha$

$\alpha$ margin typically small positive number $(0.2, 0.5, \cdot)$
???

Although we did not a do direct comparison to other
losses, e.g. the one using pairs of positives and negatives, as
used in [14] Eq. (2), we believe that the triplet loss is more
suitable for face verification. The motivation is that the loss
from [14] encourages all faces of one identity to be projected
Z onto a single point in the embedding space. The
triplet loss, however, tries to enforce a margin between each
pair of faces from one person to all other faces. This allows
the faces for one identity to live on a manifold, while
still enforcing the distance and thus discriminability to other
identities.

---
##Triplet Loss

$l(x^a, x^{+}, x^{-}) =$

$max(||f(x^a) - f(x^{+})||_2 -
                           ||f(x^a) - f(x^{-})||_2 + \alpha, 0)$

.footnote.small[
Schroff et al.,2015, FaceNet: A unified embedding for face recognition and clustering
]

--

Training

- Sample a minibatch of triplets $\{(x^a, x^{+}, x^{-})_i\}$
- Compute $\sum\_i l((x^a, x^{+}, x^{-})\_i)$
- Propagate gradients to update $f_{\theta}$

--
Also, L2 normalization of embeddings

---
## Hard negative sampling

If anchor, positive and negative are chosen randomly, gradient in one batch quickly become almost $0$

--

Number of possible triplets is huge, random sampling is inefficient

--

Schedule and choose hard triplets:

- Hard triplet sampling

$||f(x^a) - f(x^{+})||_2 > ||f(x^a) - f(x^{-})||_2 + \alpha$

- Semi Hard triplet sampling

$||f(x^a) - f(x^{+})||_2 > ||f(x^a) - f(x^{-})||_2$

---
## Triplets results

.center[
          <img src="images/facenet.png" style="width: 260px;" />
]

.footnote.small[
Schroff, Florian, et al. Facenet: A unified embedding for face recognition and clustering, CVPR 2015. = hard negative mining and semi hard
]

--

- A threshold is computed on test set ($1.2$)
- Best model achieves 99.6% verification accuracy on LFW
- Face alignment is critical!

???
Achieves a validation rate of 87% at false rate 0.001%
---
## Improving Triplets


.footnote.small[
K. Sohn. Improved deep metric learning with multi-class N-pair loss objective, NIPS 2016 <br/>
]
---
## Histogram loss

.center[
          <img src="images/histogram.png" style="width: 460px;" />
]

Compute all the **positives similarities** and **negatives similarities** within a batch

.footnote.small[
Ustinova, Evgeniya, et al. Learning deep embeddings with histogram loss, NIPS 2016
]

--

The loss pushes to **seperate** the two similarity distributions

--

Sample classes intelligently to have representative enough distributions
---
## Quadruplet loss

.center[
          <img src="images/quadruplets.png" style="width: 760px;" />
]

.footnote.small[
Huang, Chen, et al. Local similarity-aware deep feature embedding, NIPS 2016
]

--

**intraclass distance** in a high-density region may be larger than the **interclass distance** in low-density regions

---
## Quadruplet loss

.center[
          <img src="images/quadruplets.png" style="width: 760px;" />
]

.footnote.small[
Huang, Chen, et al. Local similarity-aware deep feature embedding, NIPS 2016
]

Position-Dependent Deep Metric (PDDM) depends on two points + position of mean (red triangle)

---
## Quadruplet loss

.center[
          <img src="images/quadruplets.png" style="width: 760px;" />
]

.footnote.small[
Huang, Chen, et al. Local similarity-aware deep feature embedding, NIPS 2016
]

Sample a hard quadruplet $(i,j)$ most dissimilar positive sample, and $k$ and $l$ are hard negatives

---
## Results

.center[
          <img src="images/resquad.png" style="width: 500px;" />
]

Metric: Recall @K

--

.center[
          <img src="images/reshist.png" style="width: 500px;" />
]

--

ImageNet pretrained is competitive!

---
## Getting started

Available open source implementations / pretrained models:
- Openface
- FaceNet
- DeepFace

Commercial recognition systems are trained on a large datasets like 10/100 million images

--

## Deploying

Pre-compute all the images that you are using as a comparison to the vector f(x(j))
When a new image that needs to be compared, get its vector f(x(i)) then put it with all the pre computed vectors and pass it to the sigmoid function.


???

refs
Y. Movshovitz-Attias et al. No fuss distance metric learning using proxies, NIPS 2017 = using proxies + NCA -- sota?
K. Sohn. Improved deep metric learning with multi-class N-pair loss objective, NIPS 2016 = use multiple negatives instead of one triplet
H. Oh Song, et al. Deep metric learning via lifted structured feature embedding, CVPR 2016 = using all possible examples & relations in batch - online products
O. Rippel, et al. Metric learning with adaptive density discrimination. Arxiv preprint, 2015 = magnet loss, clustering and neighborhood
Ustinova, Evgeniya, et al. Learning deep embeddings with histogram loss, NIPS 2016 = full batch, seperate positives from negatives distributions (KL divergence, histogram bins)
Huang, Chen, et al. Local similarity-aware deep feature embedding, NIPS 2016 = similar to previous, but using quadriplets
Schroff, Florian, et al. Facenet: A unified embedding for face recognition and clustering, CVPR 2015. = hard negative mining and semi hard
---
class: middle, center

# Lab 1: Room C48-C49 in 15min!

    </textarea>
    <style TYPE="text/css">
      code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
      }
      });
      MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
		     all[i].SourceElement().parentNode.className += ' has-jax';
		     }
		     });
		     </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../remark.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true
      });
    </script>
  </body>
</html>
