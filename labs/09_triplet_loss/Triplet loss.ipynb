{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face verification\n",
    "\n",
    "### Goals\n",
    "- train a network for face similarity using siamese networks\n",
    "- train a network for face similarity using triplet loss\n",
    "\n",
    "the architecture is as follows:\n",
    "\n",
    "_image_\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- We will be using Labeled Faces in the Wild (LFW) dataset available openly at _url_\n",
    "- For computing purposes, we'll only restrict ourselves to a subpart of the dataset. You're welcome to train on the whole dataset on GPU\n",
    "- We will also load pretrained weights\n",
    "\n",
    "### References\n",
    "\n",
    "- paper1\n",
    "- paper2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Concatenate, merge, Lambda, Dot\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Flatten, Dropout\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todos\n",
    "\n",
    "- ask hedi for his code\n",
    "- see what can be done in keras\n",
    "- load and split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the dataset\n",
    "\n",
    "The dataset consists of folders corresponding to each identity. The folder name is the name of the person.\n",
    "We map each class (identity) to an integer id, and build mappings as dictionaries `name_to_classid` and `classid_to_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = \"lfw-a/lfw/\"\n",
    "PATH = \"lfw/lfw-deepfunneled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = sorted(os.listdir(PATH))\n",
    "name_to_classid = {d:i for i,d in enumerate(dirs)}\n",
    "classid_to_name = {v:k for k,v in name_to_classid.items()}\n",
    "num_classes = len(name_to_classid)\n",
    "print(\"number of classes: \"+str(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each directory, there is one or more images corresponding to the identity. We map each image path with an integer id, then build a few dictionaries:\n",
    "- mappings from imagepath and image id: `path_to_id` and `id_to_path`\n",
    "- mappings from class id to image ids: `classid_to_ids` and `id_to_classid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all directories\n",
    "img_paths = {c:[directory + \"/\" + img for img in sorted(os.listdir(PATH+directory))] \n",
    "             for directory,c in name_to_classid.items()}\n",
    "\n",
    "# retrieve all images\n",
    "all_images_path = []\n",
    "for img_list in img_paths.values():\n",
    "    all_images_path += img_list\n",
    "\n",
    "# map to integers\n",
    "path_to_id = {v:k for k,v in enumerate(all_images_path)}\n",
    "id_to_path = {v:k for k,v in path_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build mappings between images and class\n",
    "classid_to_ids = {k:[path_to_id[path] for path in v] for k,v in img_paths.items()}\n",
    "id_to_classid = {v:c for c,imgs in classid_to_ids.items() for v in imgs}\n",
    "dict(list(id_to_classid.items())[0:13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following histogram shows the number of images per class: there are many classes with only one image. \n",
    "These classes are useful as negatives, only as we can't make a positive pair with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(classid_to_name[x], len(classid_to_ids[x])) for x in np.argsort([len(v) for k,v in classid_to_ids.items()])[::-1][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist([len(v) for k,v in classid_to_ids.items()], bins=range(1,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(classid_to_name[x], len(classid_to_ids[x])) for x in np.argsort([len(v) for k,v in classid_to_ids.items()])[::-1][:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### siamese nets\n",
    "\n",
    "A siamese net takes as input two images $x_1$ and $x_2$ and outputs a single value which corresponds to the similarity between $x_1$ and $x_2$.\n",
    "\n",
    "In order to train such a system, one has to build positive and negative pairs for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pos_pairs_for_id(classid, max_num=50):\n",
    "    imgs = classid_to_ids[classid]\n",
    "    if len(imgs) == 1:\n",
    "        return []\n",
    "    pos_pairs = [(imgs[i], imgs[j]) for i in range(len(imgs)) for j in range(i+1,len(imgs))]\n",
    "    random.shuffle(pos_pairs)\n",
    "    return pos_pairs[:max_num]\n",
    "\n",
    "def build_neg_pairs_for_id(classid, classes, max_num=20):\n",
    "    imgs = classid_to_ids[classid]\n",
    "    neg_classes_ids = random.sample(classes, max_num+1)\n",
    "    if classid in neg_classes_ids:\n",
    "        neg_classes_ids.remove(classid)\n",
    "    neg_pairs = []\n",
    "    for id2 in range(max_num):\n",
    "        img1 = imgs[random.randint(0,len(imgs)-1)]\n",
    "        imgs2 = classid_to_ids[neg_classes_ids[id2]]\n",
    "        img2 = imgs2[random.randint(0,len(imgs2)-1)]\n",
    "        neg_pairs += [(img1, img2)]\n",
    "    return neg_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build positive and a negative pairs for class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_pos_pairs_for_id(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_neg_pairs_for_id(5, list(range(num_classes)), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to compute the pairs, let's open all the possible images. It will expand all the images into RAM memory. There are more than 1000 images, so 250Mo of RAM will be used, which will not cause any issue.\n",
    "\n",
    "_Note: if you plan on opening more images, you should not open them all at once, and rather build a generator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def resize100(img):\n",
    "    return resize(img, (100, 100), preserve_range=True, mode='reflect')[20:80,20:80,:]\n",
    "\n",
    "def open_all_images(id_to_path):\n",
    "    all_imgs = []\n",
    "    for path in id_to_path.values():\n",
    "        all_imgs += [np.expand_dims(resize100(imread(PATH+path)),0)]\n",
    "    return np.vstack(all_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = open_all_images(id_to_path)\n",
    "all_imgs.shape, str(all_imgs.nbytes / 1e6) + \"Mo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_data(split=0.8):\n",
    "    listX1 = []\n",
    "    listX2 = []\n",
    "    listY = []\n",
    "    split = int(num_classes * split)\n",
    "    \n",
    "    # train\n",
    "    for id in range(split):\n",
    "        pos = build_pos_pairs_for_id(id)\n",
    "        neg = build_neg_pairs_for_id(id, list(range(split)))\n",
    "        for pair in pos:\n",
    "            listX1 += [pair[0]]\n",
    "            listX2 += [pair[1]]\n",
    "            listY += [1]\n",
    "        for pair in neg:\n",
    "            if sum(listY) > len(listY) / 2:\n",
    "                listX1 += [pair[0]]\n",
    "                listX2 += [pair[1]]\n",
    "                listY += [0]\n",
    "    perm = np.random.permutation(listX1)\n",
    "    X1_ids_train, X2_ids_train, Y_ids_train = np.array(listX1)[perm], np.array(listX2)[perm], np.array(listY)[perm]\n",
    "    \n",
    "    listX1 = []\n",
    "    listX2 = []\n",
    "    listY = []\n",
    "    #test\n",
    "    for id in range(split,num_classes):\n",
    "        pos = build_pos_pairs_for_id(id)\n",
    "        neg = build_neg_pairs_for_id(id, list(range(split,num_classes)))\n",
    "        for pair in pos:\n",
    "            listX1 += [pair[0]]\n",
    "            listX2 += [pair[1]]\n",
    "            listY += [1]\n",
    "        for pair in neg:\n",
    "            if sum(listY) > len(listY) / 2:\n",
    "                listX1 += [pair[0]]\n",
    "                listX2 += [pair[1]]\n",
    "                listY += [0]\n",
    "    X1_ids_test, X2_ids_test, Y_ids_test = np.array(listX1), np.array(listX2), np.array(listY)\n",
    "    return X1_ids_train, X2_ids_train, Y_ids_train, X1_ids_test, X2_ids_test, Y_ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    #iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 0.5)), # blur images with a sigma of 0 to 3.0\n",
    "    iaa.Multiply((0.5, 1.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_ids_train, X2_ids_train, train_Y, X1_ids_test, X2_ids_test, test_Y = build_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self, X1, X2, Y, batch_size, all_imgs):\n",
    "        self.cur_train_index=0\n",
    "        self.batch_size = batch_size\n",
    "        self.X1 = X1\n",
    "        self.X2 = X2\n",
    "        self.Y = Y\n",
    "        self.imgs = all_imgs\n",
    "        self.num_samples = Y.shape[0]\n",
    "        \n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            self.cur_train_index += self.batch_size\n",
    "            if self.cur_train_index >= self.num_samples:\n",
    "                self.cur_train_index=0\n",
    "            \n",
    "            imgs1 = self.X1[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs2 = self.X2[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "    \n",
    "       # deactivate augmentation\n",
    "       #     yield ([self.imgs[imgs1], self.imgs[imgs2]],\n",
    "       #             self.Y[self.cur_train_index:self.cur_train_index+self.batch_size])\n",
    "        \n",
    "            yield ([seq.augment_images(self.imgs[imgs1]), \n",
    "                    seq.augment_images(self.imgs[imgs2])\n",
    "                    ],\n",
    "                    self.Y[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(X1_ids_train, X2_ids_train, train_Y, 32, all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x1, x2], y = next(gen.next_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.vstack([x1[0:6],x2[0:6]])\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for i, X in enumerate(z):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(X / 255)\n",
    "    if i>5 and y[i-6]==1.0:\n",
    "        plt.title(\"similar\")\n",
    "    elif i>5 and y[i-6]==0.0:\n",
    "        plt.title(\"different\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = all_imgs[X1_ids_train]\n",
    "train_X2 = all_imgs[X2_ids_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_X1 = all_imgs[X1_ids_test]\n",
    "test_X2 = all_imgs[X2_ids_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X1.shape, train_X2.shape, train_Y.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_X1.shape, test_X2.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_sim(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on similarity.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred > 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((60,60,3), dtype='float32')\n",
    "x = Conv2D(16, 3, activation=\"relu\", padding=\"same\")(inp)\n",
    "x = MaxPool2D((2,2))(x) # 30,30\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 15,15\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 8,8\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 4,4\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32)(x)\n",
    "shared_conv = Model(inputs=inp, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = Input((60,60,3), dtype='float32')\n",
    "i2 = Input((60,60,3), dtype='float32')\n",
    "\n",
    "x1 = shared_conv(i1)\n",
    "x2 = shared_conv(i2)\n",
    "\n",
    "out = Dot(axes=-1, normalize=True)([x1,x2])\n",
    "\n",
    "model = Model(inputs=[i1, i2], outputs=out)\n",
    "predict_model = Model(inputs=i1, outputs=x1)\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[accuracy_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=gen.next_train(), \n",
    "                    steps_per_epoch=train_Y.shape[0] // 32, \n",
    "                    epochs=5,\n",
    "                    validation_data=([test_X1, test_X2], test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = predict_model.predict(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_emb = emb / np.linalg.norm(emb, axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_sim(x, emb, topn=5):\n",
    "    sims = np.dot(emb,x)\n",
    "    ids = np.argsort(sims)[::-1]\n",
    "    return [(id,sims[id]) for id in ids[:topn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_id(image, emb, topn=5):\n",
    "    sims = np.dot(emb,x)\n",
    "    ids = np.argsort(sims)[::-1]\n",
    "    return [(id,sims[id]) for id in ids[:topn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    img = img.astype('uint8')\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_classes = list(filter(lambda x: len(x[1])>4, classid_to_ids.items()))\n",
    "class_idx = random.choice(interesting_classes)[0]\n",
    "print(class_idx)\n",
    "img_idx = random.choice(classid_to_ids[class_idx])\n",
    "for id, sim in most_sim(norm_emb[img_idx], norm_emb):\n",
    "    display(all_imgs[id])\n",
    "    print((classid_to_name[id_to_classid[id]], id, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet loss\n",
    "\n",
    "In the triplet loss model, we'll define 3 inputs $(a,+,-)$ for anchor, positive and negative.\n",
    "\n",
    "#### usage and differences with siamese nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_triplet_for_image(imageid, classes, max_num=20):\n",
    "    classid = id_to_classid[imageid]\n",
    "    imgs = set(classid_to_ids[classid])\n",
    "    other_imgs = imgs - set([imageid])\n",
    "    negatives = random.sample(classes, len(other_imgs))\n",
    "    triplets = [(imageid, img, neg) for (img,neg) in zip(other_imgs, negatives)]\n",
    "    random.shuffle(triplets)\n",
    "    return triplets[:max_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_triplet_for_image(21, list(range(200)), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_positive_interactions = sum([len(x) * (len(x) - 1) for x in classid_to_ids.values()])\n",
    "max_positive_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGenerator():\n",
    "    def __init__(self, split, batch_size, all_imgs, max_positives=20):\n",
    "        self.cur_img_index=0\n",
    "        self.cur_img_pos_index=0\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.imgs = all_imgs\n",
    "        # build anchor and positive paris, we'll add negatives during batch generation\n",
    "        listX1 = []\n",
    "        listX2 = []\n",
    "\n",
    "        # build positive pairs\n",
    "        for id in range(split):\n",
    "            pos = build_pos_pairs_for_id(id, max_positives)\n",
    "            \n",
    "            for pair in pos:\n",
    "                listX1 += [pair[0]]\n",
    "                listX2 += [pair[1]]\n",
    "        print(listX1)\n",
    "        #shuffle positives\n",
    "        perm = np.random.permutation(listX1)\n",
    "        self.X1_ids_train = np.array(listX1)[perm]\n",
    "        self.X2_ids_train = np.array(listX2)[perm]\n",
    "        self.num_samples = len(listX1)\n",
    "        \n",
    "    def next_train(self):\n",
    "        while 1:\n",
    "            self.cur_train_index += self.batch_size\n",
    "            if self.cur_train_index >= self.num_samples:\n",
    "                self.cur_train_index=0\n",
    "            \n",
    "            # fill one batch\n",
    "            imgs1 = self.X1[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs2 = self.X2[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "            imgs3 = random.sample(split,imgs1.shape[0])\n",
    "    \n",
    "       # deactivate augmentation\n",
    "       #     yield ([self.imgs[imgs1], self.imgs[imgs2]],\n",
    "       #             self.Y[self.cur_train_index:self.cur_train_index+self.batch_size])\n",
    "        \n",
    "            yield ([seq.augment_images(self.imgs[imgs1]), \n",
    "                    seq.augment_images(self.imgs[imgs2])\n",
    "                    ],\n",
    "                    self.Y[self.cur_train_index:self.cur_train_index+self.batch_size]\n",
    "                )\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(num_classes * 0.9)\n",
    "gen = TripletGenerator(split, 32, all_imgs)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "\n",
    "def triplet_loss(X):\n",
    "    _alpha = 0.2\n",
    "    a, p, n = X\n",
    "\n",
    "    positive_distances = K.mean(K.square(a - p),axis=-1)\n",
    "    negative_distances = K.mean(K.square(a - n),axis=-1)\n",
    "    \n",
    "    # batch loss\n",
    "    losses = K.maximum(0.0, positive_distances - negative_distances + _alpha)\n",
    "    \n",
    "    return K.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalizeLayer = Lambda(lambda x: K.l2_normalize(\n",
    "                        K.sqrt(K.relu(x) + K.epsilon()) - K.sqrt(K.relu(-x)+ K.epsilon()),\n",
    "                        axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((100,100,3), dtype='float32')\n",
    "x = Conv2D(16, 3, activation=\"relu\", padding=\"same\")(inp)\n",
    "x = MaxPool2D((2,2))(x) # 50,50\n",
    "x = Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 25,25\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 12,12\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPool2D((2,2))(x) # 6,6\n",
    "x = Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64)(x)\n",
    "shared_conv2 = Model(inputs=inp, outputs = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tech details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = merge(\n",
    "    [a, p, n],\n",
    "    mode=triplet_loss,\n",
    "    name='loss',\n",
    "    output_shape=(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = Input((100, 100, 3), name='anchor')\n",
    "positive = Input((100, 100, 3), name='positive')\n",
    "negative = Input((100, 100, 3), name='negative')\n",
    "\n",
    "a = shared_conv2(anchor)\n",
    "p = shared_conv2(positive)\n",
    "n = shared_conv2(negative)\n",
    "\n",
    "loss = Lambda(triplet_loss,\n",
    "                      output_shape=(1,))(\n",
    "                      [a,p,n])\n",
    "\n",
    "model_triplet = Model(\n",
    "    inputs=[anchor, positive, negative],\n",
    "    outputs=loss)\n",
    "\n",
    "predict_model_triplet = Model(inputs=anchor, outputs=a)\n",
    "model_triplet.compile(loss=identity_loss, optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(size=(90,100,100,3))\n",
    "print(x.shape)\n",
    "triplet = [x[0:30,:], x[30:60,:], x[60:90,:]]\n",
    "model_triplet.fit(x=triplet, \n",
    "          y=np.zeros(30),\n",
    "          epochs=100, batch_size=10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = predict_model_triplet.predict(x[0:90])\n",
    "tsne_out = TSNE(perplexity=30).fit_transform(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"blue\"]*30 + [\"green\"]*30 + [\"red\"]*30\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(tsne_out[0:90, 0], tsne_out[0:90, 1], c=colors);\n",
    "plt.xticks(()); plt.yticks(());\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(out[0]-out, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,100)\n",
    "\n",
    "for id, sim in most_sim(norm_emb[idx], norm_emb):\n",
    "    display(all_imgs[id])\n",
    "    print((id,sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constrastive loss and euclidean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean( y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = Input((100,100,3), dtype='float32')\n",
    "i2 = Input((100,100,3), dtype='float32')\n",
    "\n",
    "x1 = shared_conv(i1)\n",
    "x2 = shared_conv(i2)\n",
    "\n",
    "#out = Dot(axes=-1, normalize=True)([x1,x2])\n",
    "out = Lambda(euclidean_distance, output_shape=(1,))([x1, x2])\n",
    "\n",
    "\n",
    "model = Model(inputs=[i1, i2], outputs=out)\n",
    "predict_model = Model(inputs=i1, outputs=x1)\n",
    "model.compile(loss=contrastive_loss, optimizer=\"rmsprop\", metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([train_X1, train_X2], train_Y,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=([test_X1, test_X2], test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
