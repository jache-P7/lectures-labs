{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time\n",
    "import os.path as op\n",
    "import gzip\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tfe.enable_eager_execution()\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "def get_data_format():\n",
    "    return 'channels_first' if tfe.num_gpus() else 'channels_last'\n",
    "\n",
    "def get_device():\n",
    "    return \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\n",
    "\n",
    "\n",
    "print(get_device(), get_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(images_train, labels_train), (images_test, labels_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAMES = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_image_shape(image_size=(28, 28), data_format=None):\n",
    "    if data_format is None:\n",
    "        data_format = get_data_format()\n",
    "    if data_format == 'channels_first':\n",
    "        return (-1, 1) + image_size\n",
    "    elif data_format == 'channels_last':\n",
    "        return (-1,) + image_size + (1,)\n",
    "    else:\n",
    "        raise ValueError('invalid format: %r' % data_format)\n",
    "        \n",
    "get_batch_image_shape((28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = images_train.reshape(get_batch_image_shape((28, 28)))\n",
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = images_test.reshape(get_batch_image_shape((28, 28)))\n",
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_gallery(images, labels):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if hasattr(images, 'numpy'):\n",
    "        images = images.numpy()\n",
    "    for i, image, label in zip(range(12), images, labels):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.imshow(image.reshape(28, 28), cmap=plt.cm.gray)\n",
    "        plt.title(TARGET_NAMES[label])\n",
    "        plt.axis('off')\n",
    "\n",
    "        \n",
    "plot_sample_gallery(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(num_classes, y):\n",
    "    return np.eye(num_classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_images_train = images_train.astype(np.float32) / 255\n",
    "scaled_images_test = images_test.astype(np.float32) / 255\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (scaled_images_train, onehot_encode(10, labels_train)))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (scaled_images_test, onehot_encode(10, labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_images_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_sample_gallery(scaled_images_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_image_data_augment(image):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=63 / 255.0)\n",
    "    image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "    return image\n",
    "\n",
    "\n",
    "def data_augment(input_tensor):\n",
    "    return tf.map_fn(single_image_data_augment, input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot some data augmented samples. **Rerun the execution of this sell several times using `ctrl-enter`** to see the random changes in constrast and horizontal flips happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_gallery(data_augment(images_train[:12]), labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample a small training set with labels\n",
    "iterator = tfe.Iterator(train_ds.shuffle(60000).batch(1000))\n",
    "small_train_images, small_train_labels = next(iterator)\n",
    "small_val_images, small_val_labels = next(iterator)\n",
    "small_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (small_train_images, small_train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tfe.Network):\n",
    "\n",
    "    def __init__(self, data_format, dropout=0.5):\n",
    "        super(Model, self).__init__(name='fashion-mnist')\n",
    "        self._input_shape = get_batch_image_shape(\n",
    "            image_size=(28, 28), data_format=data_format)\n",
    "        self.conv1 = self.track_layer(\n",
    "            tf.layers.Conv2D(32, 5, data_format=data_format, activation=tf.nn.relu))\n",
    "        self.conv2 = self.track_layer(\n",
    "            tf.layers.Conv2D(64, 5, data_format=data_format, activation=tf.nn.relu))\n",
    "        self.fc1 = self.track_layer(tf.layers.Dense(1024, activation=tf.nn.relu))\n",
    "        self.fc2 = self.track_layer(tf.layers.Dense(10))\n",
    "        self.dropout = self.track_layer(tf.layers.Dropout(dropout))\n",
    "        self.max_pool2d = self.track_layer(\n",
    "            tf.layers.MaxPooling2D(\n",
    "                (2, 2), (2, 2), padding='SAME', data_format=data_format))\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Compute the forward pass by plugin the parameterized layers\n",
    "        # of the model along with parameter-free operations such as\n",
    "        # max pooling and dropout.\n",
    "        # The graph of the model is dynamically defined each time\n",
    "        # we execute this forward pass.\n",
    "        x = tf.reshape(inputs, self._input_shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_from_logits(logits, targets):\n",
    "    return tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "             labels=targets, logits=logits))\n",
    "\n",
    "\n",
    "def loss(model, inputs, targets):\n",
    "    return loss_from_logits(model.call(inputs), targets)\n",
    "\n",
    "\n",
    "def accuracy_from_logits(logits, targets):\n",
    "    match = tf.equal(tf.argmax(logits, axis=1, output_type=tf.int32),\n",
    "                     tf.argmax(targets, axis=1, output_type=tf.int32))\n",
    "    return tf.reduce_mean(tf.cast(match, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(get_data_format(), dropout=0.5)\n",
    "model_ewa = Model(get_data_format(), dropout=0.5)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "grad = tfe.implicit_gradients(loss)\n",
    "\n",
    "train_duration = 0\n",
    "with tf.device(get_device()):\n",
    "    for e in range(101):\n",
    "        if e % 10 == 0:\n",
    "            tic = time()\n",
    "            train_loss = loss(model, small_train_images, small_train_labels).numpy()\n",
    "            val_logits = model.call(small_val_images)\n",
    "            val_loss = loss_from_logits(val_logits, small_val_labels).numpy()\n",
    "            val_acc = accuracy_from_logits(val_logits, small_val_labels).numpy()\n",
    "            eval_duration = time() - tic\n",
    "            print(\"Epoch %d: train loss %f, val loss %f, val acc %0.3f, train time %0.3fs, eval time %0.3fs\" %\n",
    "                  (e, train_loss, val_loss, val_acc, train_duration, eval_duration))\n",
    "        tic = time()\n",
    "        for (inputs, targets) in tfe.Iterator(small_train_ds.shuffle(1000).batch(50)):\n",
    "            optimizer.apply_gradients(grad(model, data_augment(inputs), targets, training=True))\n",
    "        train_duration = time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test_images, dataset_test_labels = next(tfe.Iterator(test_ds.batch(1000)))\n",
    "print(\"Loss on test set: %0.4f\" % loss(\n",
    "    model, dataset_test_images, dataset_test_labels).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = model.predict(scaled_images_test).numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.mean(labels_pred == labels_test)\n",
    "print(\"Accuracy on test set: %0.3f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ewa.predict(scaled_images_test).numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1w = model_ewa.conv1.trainable_variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ewa.conv1.trainable_variables[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
